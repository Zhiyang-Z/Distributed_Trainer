# @package _group_
vocabulary_size: 65
embedding_size: 768
training_seq_len: 64
need_padding: False
padding_token: 0
nlayer: [8,8]
nhead: 12
ndim: 768
ndim_feedforward: 2048
drop_out: 0.1
lr: 0.0001
betas: [0.9, 0.98]